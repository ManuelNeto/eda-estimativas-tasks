---
title: "EDA SIP"
output: html_notebook
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
source(here::here("code/lib.R"))
theme_set(theme_bw())

knitr::opts_chunk$set(tidy = FALSE,
                      fig.width = 6,
                      fig.height = 5,
                      echo = FALSE)

```

```{r read}
estimativas_raw = read_projectdata()
```


```{r}
estimativas = estimativas_raw %>%
    group_by(ProjectCode, TaskNumber, Category, Priority, Summary) %>%
    summarise(
        HoursEstimate = mean(HoursEstimate),
        HoursActual = mean(HoursActual),
        DeveloperPerformance = mean(DeveloperPerformance)
    ) %>%
    ungroup()
```

### Dados por time

```{r}
por_time = estimativas_raw %>% 
    group_by(ProjectCode) %>% 
    summarise(devs = NROW(unique(DeveloperID)), 
              erro_medio_abs = mean(abs(HoursEstimate - HoursActual)), 
              estimativas = n())

```


## Qual a relação entre as estimativas e horas reais tomadas na empresa como um todo e em diferentes categorias de tarefa?

    Para resolver essa primeira questão, filtrei as tasks com StatusCode "COMPLETED" ou "FINISHED" para ter uma melhor análise sobre as estimativas, visto que será relevante apenas os valor finais das horas trabalhadas em uma task para comparação com as horas estimadas. Ainda realizei um filtro para selecionar apenas as tasks que possuam algum valor em HoursEstimate e HoursActual. As tasks foram agrupadas por ProjectCode, TaskNumber, Category, Priority, Summary e para as taks com mais de uma estimativa e horas trabalhadas, foi utilizado a média desses valores. 
    
```{r}
estimativas = estimativas_raw %>%
    filter(StatusCode == "COMPLETED" | StatusCode == "FINISHED", !is.na(HoursEstimate), !is.na(HoursActual)) %>%
        group_by(ProjectCode, TaskNumber, Category, Priority, Summary) %>%
        summarise(
            HoursEstimate = mean(HoursEstimate),
            HoursActual = mean(HoursActual),
            DeveloperPerformance = mean(DeveloperPerformance)
        ) %>%
        ungroup()

estimativas %>% 
     ggplot(aes(x = HoursEstimate, y = HoursActual)) + 
     geom_point(color = "#7B68EE") +
     geom_rug(alpha = .7,
               color = "#9370DB",
               sides = "l") +
     labs(
        title = "Relação entre as horas estimadas e as reais",
        subtitle = "Empresa como um todo",
        x = "Horas Estimadas",
        y = "Horas Reais"
     ) + 
     scale_y_continuous(trans="log2")+
     scale_x_continuous(trans="log2")

estimativas %>%
    summarise(
        pearson = cor(HoursEstimate, HoursActual, method = "pearson"), 
        spearman = cor(HoursEstimate, HoursActual, method = "spearman"), 
        kendall = cor(HoursEstimate, HoursActual, method = "kendall")
    ) 

estimativas %>%
    filter(Category == "Development") %>%
    ggplot(aes(x=HoursEstimate, y=HoursActual))+
    geom_point(colour = "#A9A9A9") +
    geom_rug(alpha = .7,
               color = "#C0C0C0",
               sides = "l") +
    labs(
        title = "Relação entre as horas estimadas e as reais ",
        subtitle = "Categoria Development",
        x = "Horas Estimadas",
        y = "Horas Reais"
      ) +
    scale_y_continuous(trans="log2")+
    scale_x_continuous(trans="log2")

estimativas %>%
    filter(Category == "Operational") %>%
    ggplot(aes(x=HoursEstimate, y=HoursActual, colour=Category))+
    geom_point(colour = "#00BFFF") +
    geom_rug(alpha = .7,
               color = "#87CEFA",
               sides = "l") +
    labs(
        title = "Relação entre as horas estimadas e as reais ",
        subtitle = "Categoria Operational",
        x = "Horas Estimadas",
        y = "Horas Reais"
    ) +
    scale_y_continuous(trans="log2")+
    scale_x_continuous(trans="log2")

estimativas %>%
    filter(Category == "Management") %>%
    ggplot(aes(x=HoursEstimate, y=HoursActual))+
    geom_point(colour = "#FF6347") +
    geom_rug(alpha = .7,
               color = "#FF7F50",
               sides = "l") +
    labs(
        title = "Relação entre as horas estimadas e as reais ",
        subtitle = "Categoria Management",
        x = "Horas Estimadas",
        y = "Horas Reais"
      ) +
    scale_y_continuous(trans="log2")+
    scale_x_continuous(trans="log2")



estimativas %>%
    group_by(Category) %>%
    summarise(
        pearson = cor(HoursEstimate, HoursActual, method = "pearson"), 
        spearman = cor(HoursEstimate, HoursActual, method = "spearman"), 
        kendall = cor(HoursEstimate, HoursActual, method = "kendall")
    ) 


```

    Para responder a primeira pergunta, analisamos o primeiro gráfico que relaciona as horas estimadas com as horas reais para uma dada empresa. Nota-se uma grande concentração de pontos entre 1 e 16 horas reais e estimadas. Observa-se a distribuição dos pontos em formato de uma reta ascendente, comprovada com os altos valores para os métodos de Spearman e Kendall. Existe uma forte relação entre as horas estimadas e as horas reais, mostrando que no geral, o erro médio entre a estimativa e as horas reais não é tão grande.
    A divisão por categorias segue mais ou menos o mesmo padrão encontrado para o todo, grande concentração entre 1 e 16 horas, com um erro médio moderado. Destaca-se a relação entre estimativa e horas reais para a categoria Operacional, ela é a que possui o maior coeficiente linear entre todas as categorias. Conclui-se que tasks da categoria operacional são melhor estimadas.
  


## Equipes com mais desenvolvedores produzem estimativas com mais ou menos erro que equipes menores? 


    Nessa segunda questão, agrupamos as tasks pelo ProjectCode. Foi feito o cálculo do erro médio da estimativa por equipes levando em consideração a diferença entre horas estimadas e horas reais. Foi contabilizado também o número de desenvolvedores por equipe. Por fim, filtrei os dados com erro médio menor que 15 e descartei os que não possuíam dados de número de desenvolvedores e erro médio.



```{r}

por_time = estimativas_raw %>% 
    group_by(ProjectCode) %>% 
    summarise(devs = NROW(unique(DeveloperID)), 
              erro_medio_abs = mean(abs(HoursEstimate - HoursActual)), 
              estimativas = n())

por_time%>%
    filter(erro_medio_abs < 15 ,!is.na(devs), !is.na(erro_medio_abs)) %>% 
    ggplot(aes(x = devs, y = erro_medio_abs)) + 
    geom_point(color = "#CD853F") + 
    geom_rug(alpha = .7,
               color = "#D2691E",
               sides = "l") +
    labs(
        title = "Relação entre o número de desenvolvedores em uma equipe \n e a produção de estimativas com erros",
        subtitle = "",
        x = "Número de desenvolvedores",
        y = "Erro médio absoluto"
    ) + 
    scale_x_log10() + 
    scale_y_log10()

por_time %>%
    summarise(
        pearson = cor(devs, erro_medio_abs, method = "pearson"), 
        spearman = cor(devs, erro_medio_abs, method = "spearman"), 
        kendall = cor(devs, erro_medio_abs, method = "kendall")
    ) 
    

```

    Após o tratamento dos dados, restaram apenas 16 equipes para realização da análise dos dados. Nota-se uma moderada dispersão dos pontos no gráfico, comprovada pelos baixos valores nos cálculos para coeficiente angular nos três métodos. Observa-se que o erro médio absoluto é maior para equipes com número de desenvolvedores entre 8 e 16, porém o número de equipes com mais desenvolvedores é maior. Conclui-se portanto que equipes com maior número de desenvolvedores tendem a produzir estimativas com mais erros.
